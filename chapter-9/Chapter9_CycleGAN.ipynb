{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import VisionDataset, ImageFolder\n",
    "from torchvision.datasets.utils import check_integrity, download_and_extract_archive\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch or torchvision does not come with the `apple2orange` dataset. Therefore we implement a full dataset which retrieves the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apple2Orange(VisionDataset):\n",
    "    url = \"https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/apple2orange.zip\"\n",
    "    base_folder = \"apple2orange\"\n",
    "    filename = \"apple2orange.zip\"\n",
    "    zip_md5 = \"5b58c340256288622a835d6f3b6198ae\"\n",
    "    \n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "             download=False):\n",
    "        super().__init__(root, transform=transform,\n",
    "                            target_transform=target_transform)\n",
    "        self.train = train\n",
    "        self.train_folder = os.path.join(self.root, self.base_folder, \"train\")\n",
    "        self.test_folder = os.path.join(self.root, self.base_folder, \"test\")\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "            \n",
    "        if train:\n",
    "            root = self.train_folder\n",
    "        else:\n",
    "            root = self.test_folder\n",
    "            \n",
    "        self.dataset = ImageFolder(root, transform, target_transform)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "            \n",
    "    def _check_integrity(self):\n",
    "        fpath = os.path.join(self.root, self.filename)\n",
    "        \n",
    "        if check_integrity(fpath, self.zip_md5) and os.path.exists(os.path.join(self.root, self.base_folder)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "            \n",
    "    def download(self):\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "        \n",
    "        #download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.zip_md5)\n",
    "        \n",
    "        train_path = os.path.join(self.root, self.base_folder, \"train\")\n",
    "        test_path = os.path.join(self.root, self.base_folder, \"test\")\n",
    "        source_train_a = os.path.join(self.root, self.base_folder, \"trainA\")\n",
    "        source_train_b = os.path.join(self.root, self.base_folder, \"trainB\")\n",
    "        source_test_a = os.path.join(self.root, self.base_folder, \"testA\")\n",
    "        source_test_b = os.path.join(self.root, self.base_folder, \"testB\")\n",
    "        \n",
    "        os.mkdir(train_path)\n",
    "        os.mkdir(test_path)\n",
    "        \n",
    "        os.renames(source_train_a, os.path.join(train_path, \"apple\"))\n",
    "        os.renames(source_train_b, os.path.join(train_path, \"orange\"))\n",
    "        os.renames(source_test_a, os.path.join(test_path, \"apple\"))\n",
    "        os.renames(source_test_b, os.path.join(test_path, \"orange\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "t = Compose([Resize(128), ToTensor()])\n",
    "train_set = Apple2Orange('~/pytorch', train=True, download=True, transform=t)\n",
    "test_set = Apple2Orange('~/pytorch', train=False, download=True, transform=t)\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    class TransSkip(nn.Module):\n",
    "        def __init__(self, in_channel, out_channel, kernel_size):\n",
    "            super().__init__()\n",
    "            self.trans1 = nn.Sequential(\n",
    "                nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size, stride=1, padding=int(kernel_size/2)),\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.InstanceNorm2d(out_channel/2))\n",
    "            \n",
    "        def forward(self, x, skip):\n",
    "            trans = self.trans1(x)\n",
    "            x = torch.cat([trans,  skip], dim=1)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.conv_layer(3, 32, 3)\n",
    "        self.conv2 = self.conv_layer(32, 64, 3)\n",
    "        self.conv3 = self.conv_layer(64, 128, 3)\n",
    "        self.conv4 = self.conv_layer(128, 256, 3)\n",
    "        \n",
    "        self.trans1 = self.TransSkip(256, 128, 3)\n",
    "        self.trans2 = self.TransSkip(256, 64, 3)\n",
    "        self.trans3 = self.TransSkip(128, 32, 3)\n",
    "        # Check if using skip from first image improves result\n",
    "        # self.trans4 = self.TransSkip(64, 64, 3)\n",
    "        # self.conv5 = nn.Sequential(\n",
    "        #     nn.Conv2d(67, 3, 3, stride=1, padding=1),\n",
    "        #     nn.Tanh())\n",
    "        self.trans4 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_0 = x\n",
    "        skip_1 = x = self.conv1(x)\n",
    "        skip_2 = x = self.conv2(x)\n",
    "        skip_3 = x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.trans1(x, skip_3)\n",
    "        x = self.trans2(x, skip_2)\n",
    "        x = self.trans3(x, skip_1)\n",
    "        # x = self.trans4(x, skip_0)\n",
    "        x = self.trans4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm2d(out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = generator(torch.randn(8, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 128, 128])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.conv_layer(3, 64, 3)\n",
    "        self.conv2 = self.conv_layer(64, 128, 3)\n",
    "        self.conv3 = self.conv_layer(128, 256, 3)\n",
    "        self.conv4 = self.conv_layer(256, 512, 3)\n",
    "        self.conv5 = nn.Conv2d(512, 1, 4, stride=1, padding=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=2, padding=int(kernel_size/2)),\n",
    "            nn.LeakyReLU(negative_slope=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = discriminator(torch.randn(8, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 9, 9])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
